obiwan
pid: 733201
conda env: greaselm
screen: 

gpu: 0,1

Namespace(att_head_num=2, batch_size=128, cuda=True, dataset='nephqa', debug=False, decoder_lr=0.001, dev_adj='data/nephqa/graph/dev.graph.adj.pk', dev_statements='data/nephqa/statement/dev.statement.jsonl', drop_partial_batch=False, dropoutf=0.2, dropoutg=0.2, dropouti=0.2, encoder='roberta-large', encoder_layer=-1, encoder_lr=1e-05, ent_emb=['tzw'], ent_emb_paths=['data/cpnet/tzw.ent.npy'], eval_batch_size=2, fc_dim=200, fc_layer_num=0, fill_partial_batch=False, fp16=True, freeze_ent_emb=True, gnn_dim=200, inhouse=False, inhouse_train_qids='data/nephqa/inhouse_split_qids.txt', init_range=0.02, k=5, load_model_path=None, log_interval=10, loss='cross_entropy', lr_schedule='fixed', max_epochs_before_stop=50, max_grad_norm=1.0, max_node_num=200, max_seq_len=100, mini_batch_size=1, mode='train', n_epochs=100, num_relation=38, optim='radam', refreeze_epoch=10000, save_dir='saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348', save_model=True, seed=0, simple=False, subsample=1.0, test_adj='data/nephqa/graph/test.graph.adj.pk', test_statements='data/nephqa/statement/test.statement.jsonl', train_adj='data/nephqa/graph/train.graph.adj.pk', train_statements='data/nephqa/statement/train.statement.jsonl', unfreeze_epoch=4, use_cache=True, warmup_steps=150, weight_decay=0.01)
| num_concepts: 799273 |
train_statement_path data/nephqa/statement/train.statement.jsonl
num_choice 5
| ori_adj_len: mu 22.09 sigma 27.50 | adj_len: 22.98 | prune_rate： 0.00 | qc_num: 3.94 | ac_num: 1.20 |
| ori_adj_len: mu 22.74 sigma 29.45 | adj_len: 23.73 | prune_rate： 0.00 | qc_num: 3.89 | ac_num: 1.29 |
| ori_adj_len: mu 22.53 sigma 26.64 | adj_len: 23.37 | prune_rate： 0.00 | qc_num: 3.78 | ac_num: 1.18 |
args.num_relation 38
parameters:
	concept_emb.emb.weight                       	fixed	torch.Size([799273, 1024])	device:cuda:1
	concept_emb.cpt_transform.weight             	trainable	torch.Size([200, 1024])	device:cuda:1
	concept_emb.cpt_transform.bias               	trainable	torch.Size([200])	device:cuda:1
	svec2nvec.weight                             	trainable	torch.Size([200, 1024])	device:cuda:1
	svec2nvec.bias                               	trainable	torch.Size([200])	device:cuda:1
	gnn.emb_node_type.weight                     	trainable	torch.Size([100, 4])	device:cuda:1
	gnn.emb_node_type.bias                       	trainable	torch.Size([100])	device:cuda:1
	gnn.emb_score.weight                         	trainable	torch.Size([100, 100])	device:cuda:1
	gnn.emb_score.bias                           	trainable	torch.Size([100])	device:cuda:1
	gnn.edge_encoder.0.weight                    	trainable	torch.Size([200, 47])	device:cuda:1
	gnn.edge_encoder.0.bias                      	trainable	torch.Size([200])	device:cuda:1
	gnn.edge_encoder.1.weight                    	trainable	torch.Size([200])	device:cuda:1
	gnn.edge_encoder.1.bias                      	trainable	torch.Size([200])	device:cuda:1
	gnn.edge_encoder.3.weight                    	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.edge_encoder.3.bias                      	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.0.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.0.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.0.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.0.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.0.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.1.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.1.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.1.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.1.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.1.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.2.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.2.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.2.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.2.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.2.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.3.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.3.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.3.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.3.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.3.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.4.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.4.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.4.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.4.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.4.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.Vh.weight                                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.Vh.bias                                  	trainable	torch.Size([200])	device:cuda:1
	gnn.Vx.weight                                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.Vx.bias                                  	trainable	torch.Size([200])	device:cuda:1
	pooler.w_qs.weight                           	trainable	torch.Size([200, 1024])	device:cuda:1
	pooler.w_qs.bias                             	trainable	torch.Size([200])	device:cuda:1
	pooler.w_ks.weight                           	trainable	torch.Size([200, 200])	device:cuda:1
	pooler.w_ks.bias                             	trainable	torch.Size([200])	device:cuda:1
	pooler.w_vs.weight                           	trainable	torch.Size([200, 200])	device:cuda:1
	pooler.w_vs.bias                             	trainable	torch.Size([200])	device:cuda:1
	fc.layers.0-Linear.weight                    	trainable	torch.Size([1, 1424])	device:cuda:1
	fc.layers.0-Linear.bias                      	trainable	torch.Size([1])	device:cuda:1
	total: 2845025

-----------------------------------------------------------------------
Using fp16 training
-----------------------------------------------------------------------
| epoch   0 | step     9 | dev_acc  0.1803 | test_acc  0.1674 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.0
| step     9 |  lr: 0.0000100 | loss  1.6204 | ms/batch  482.97 |
-----------------------------------------------------------------------
| epoch   1 | step    18 | dev_acc  0.2131 | test_acc  0.2326 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.1
| step    19 |  lr: 0.0000100 | loss  1.6173 | ms/batch  966.26 |
-----------------------------------------------------------------------
| epoch   2 | step    27 | dev_acc  0.2459 | test_acc  0.1767 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.2
| step    29 |  lr: 0.0000100 | loss  1.6122 | ms/batch 1488.54 |
-----------------------------------------------------------------------
| epoch   3 | step    36 | dev_acc  0.2131 | test_acc  0.1953 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.3
| step    39 |  lr: 0.0000100 | loss  1.6182 | ms/batch 3724.47 |
-----------------------------------------------------------------------
| epoch   4 | step    45 | dev_acc  0.1967 | test_acc  0.2279 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.4
| step    49 |  lr: 0.0000100 | loss  1.6205 | ms/batch 4671.17 |
-----------------------------------------------------------------------
| epoch   5 | step    54 | dev_acc  0.2295 | test_acc  0.1628 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.5
| step    59 |  lr: 0.0000100 | loss  1.6187 | ms/batch 5625.65 |
-----------------------------------------------------------------------
| epoch   6 | step    63 | dev_acc  0.2623 | test_acc  0.1721 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.6
| step    69 |  lr: 0.0000100 | loss  1.6205 | ms/batch 6552.18 |
-----------------------------------------------------------------------
| epoch   7 | step    72 | dev_acc  0.2623 | test_acc  0.2047 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.7
| step    79 |  lr: 0.0000100 | loss  1.6218 | ms/batch 7500.94 |
-----------------------------------------------------------------------
| epoch   8 | step    81 | dev_acc  0.1967 | test_acc  0.1814 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.8
| step    89 |  lr: 0.0000100 | loss  1.6169 | ms/batch 8406.89 |
-----------------------------------------------------------------------
| epoch   9 | step    90 | dev_acc  0.2213 | test_acc  0.1721 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.9
-----------------------------------------------------------------------
| epoch  10 | step    99 | dev_acc  0.2131 | test_acc  0.2047 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.10
| step    99 |  lr: 0.0000100 | loss  1.6117 | ms/batch  995.16 |
-----------------------------------------------------------------------
| epoch  11 | step   108 | dev_acc  0.2131 | test_acc  0.1814 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.11
| step   109 |  lr: 0.0000100 | loss  1.6091 | ms/batch 1994.20 |
-----------------------------------------------------------------------
| epoch  12 | step   117 | dev_acc  0.2541 | test_acc  0.2186 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.12
| step   119 |  lr: 0.0000100 | loss  1.6238 | ms/batch 2988.58 |
-----------------------------------------------------------------------
| epoch  13 | step   126 | dev_acc  0.2049 | test_acc  0.2512 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.13
| step   129 |  lr: 0.0000100 | loss  1.6133 | ms/batch 3988.75 |
-----------------------------------------------------------------------
| epoch  14 | step   135 | dev_acc  0.2541 | test_acc  0.2744 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.14
| step   139 |  lr: 0.0000100 | loss  1.6142 | ms/batch 5005.38 |
-----------------------------------------------------------------------
| epoch  15 | step   144 | dev_acc  0.1967 | test_acc  0.2605 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.15
| step   149 |  lr: 0.0000100 | loss  1.6110 | ms/batch 6012.55 |
-----------------------------------------------------------------------
| epoch  16 | step   153 | dev_acc  0.1967 | test_acc  0.1953 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.16
| step   159 |  lr: 0.0000100 | loss  1.6058 | ms/batch 7094.39 |
-----------------------------------------------------------------------
| epoch  17 | step   162 | dev_acc  0.2295 | test_acc  0.2186 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.17
| step   169 |  lr: 0.0000100 | loss  1.5896 | ms/batch 7981.48 |
-----------------------------------------------------------------------
| epoch  18 | step   171 | dev_acc  0.2049 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.18
| step   179 |  lr: 0.0000100 | loss  1.5878 | ms/batch 8563.30 |
-----------------------------------------------------------------------
| epoch  19 | step   180 | dev_acc  0.1967 | test_acc  0.2419 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.19
-----------------------------------------------------------------------
| epoch  20 | step   189 | dev_acc  0.2295 | test_acc  0.2233 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.20
| step   189 |  lr: 0.0000100 | loss  1.5701 | ms/batch  992.34 |
-----------------------------------------------------------------------
| epoch  21 | step   198 | dev_acc  0.2049 | test_acc  0.2326 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.21
| step   199 |  lr: 0.0000100 | loss  1.5574 | ms/batch 1983.88 |
-----------------------------------------------------------------------
| epoch  22 | step   207 | dev_acc  0.2623 | test_acc  0.2605 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.22
| step   209 |  lr: 0.0000100 | loss  1.5472 | ms/batch 3069.77 |
-----------------------------------------------------------------------
| epoch  23 | step   216 | dev_acc  0.2623 | test_acc  0.2326 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.23
| step   219 |  lr: 0.0000100 | loss  1.5233 | ms/batch 3959.32 |
-----------------------------------------------------------------------
| epoch  24 | step   225 | dev_acc  0.2541 | test_acc  0.2698 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.24
| step   229 |  lr: 0.0000100 | loss  1.5258 | ms/batch 4922.16 |
-----------------------------------------------------------------------
| epoch  25 | step   234 | dev_acc  0.2869 | test_acc  0.2558 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.25
| step   239 |  lr: 0.0000100 | loss  1.4806 | ms/batch 6026.90 |
-----------------------------------------------------------------------
| epoch  26 | step   243 | dev_acc  0.2295 | test_acc  0.2000 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.26
| step   249 |  lr: 0.0000100 | loss  1.4629 | ms/batch 6966.69 |
-----------------------------------------------------------------------
| epoch  27 | step   252 | dev_acc  0.2459 | test_acc  0.2372 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.27
| step   259 |  lr: 0.0000100 | loss  1.4172 | ms/batch 8042.67 |
-----------------------------------------------------------------------
| epoch  28 | step   261 | dev_acc  0.2623 | test_acc  0.2326 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.28
| step   269 |  lr: 0.0000100 | loss  1.3830 | ms/batch 8651.27 |
-----------------------------------------------------------------------
| epoch  29 | step   270 | dev_acc  0.2951 | test_acc  0.2372 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.29
-----------------------------------------------------------------------
| epoch  30 | step   279 | dev_acc  0.3279 | test_acc  0.2558 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.30
| step   279 |  lr: 0.0000100 | loss  1.3487 | ms/batch  937.04 |
-----------------------------------------------------------------------
| epoch  31 | step   288 | dev_acc  0.2787 | test_acc  0.2512 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.31
| step   289 |  lr: 0.0000100 | loss  1.3415 | ms/batch 1881.46 |
-----------------------------------------------------------------------
| epoch  32 | step   297 | dev_acc  0.2541 | test_acc  0.2186 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.32
| step   299 |  lr: 0.0000100 | loss  1.2618 | ms/batch 2799.07 |
-----------------------------------------------------------------------
| epoch  33 | step   306 | dev_acc  0.2787 | test_acc  0.2512 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.33
| step   309 |  lr: 0.0000100 | loss  1.1869 | ms/batch 3755.38 |
-----------------------------------------------------------------------
| epoch  34 | step   315 | dev_acc  0.3197 | test_acc  0.2512 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.34
| step   319 |  lr: 0.0000100 | loss  1.1751 | ms/batch 4674.88 |
-----------------------------------------------------------------------
| epoch  35 | step   324 | dev_acc  0.3361 | test_acc  0.2791 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.35
| step   329 |  lr: 0.0000100 | loss  1.0791 | ms/batch 5613.88 |
-----------------------------------------------------------------------
| epoch  36 | step   333 | dev_acc  0.3197 | test_acc  0.2698 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.36
| step   339 |  lr: 0.0000100 | loss  1.0449 | ms/batch 6572.05 |
-----------------------------------------------------------------------
| epoch  37 | step   342 | dev_acc  0.3279 | test_acc  0.2930 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.37
| step   349 |  lr: 0.0000100 | loss  0.9623 | ms/batch 7491.00 |
-----------------------------------------------------------------------
| epoch  38 | step   351 | dev_acc  0.3197 | test_acc  0.2837 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.38
| step   359 |  lr: 0.0000100 | loss  0.8941 | ms/batch 7987.14 |
-----------------------------------------------------------------------
| epoch  39 | step   360 | dev_acc  0.3525 | test_acc  0.2744 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.39
-----------------------------------------------------------------------
| epoch  40 | step   369 | dev_acc  0.3689 | test_acc  0.2977 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.40
| step   369 |  lr: 0.0000100 | loss  0.8432 | ms/batch  936.27 |
-----------------------------------------------------------------------
| epoch  41 | step   378 | dev_acc  0.3607 | test_acc  0.2791 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.41
| step   379 |  lr: 0.0000100 | loss  0.8085 | ms/batch 1876.18 |
-----------------------------------------------------------------------
| epoch  42 | step   387 | dev_acc  0.3525 | test_acc  0.2977 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.42
| step   389 |  lr: 0.0000100 | loss  0.7119 | ms/batch 2814.55 |
-----------------------------------------------------------------------
| epoch  43 | step   396 | dev_acc  0.3852 | test_acc  0.2651 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.43
| step   399 |  lr: 0.0000100 | loss  0.7334 | ms/batch 3761.55 |
-----------------------------------------------------------------------
| epoch  44 | step   405 | dev_acc  0.3525 | test_acc  0.2977 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.44
| step   409 |  lr: 0.0000100 | loss  0.6172 | ms/batch 4677.36 |
-----------------------------------------------------------------------
| epoch  45 | step   414 | dev_acc  0.3115 | test_acc  0.2791 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.45
| step   419 |  lr: 0.0000100 | loss  0.6136 | ms/batch 5610.93 |
-----------------------------------------------------------------------
| epoch  46 | step   423 | dev_acc  0.3197 | test_acc  0.2837 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.46
| step   429 |  lr: 0.0000100 | loss  0.5664 | ms/batch 6538.01 |
-----------------------------------------------------------------------
| epoch  47 | step   432 | dev_acc  0.3197 | test_acc  0.2419 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.47
| step   439 |  lr: 0.0000100 | loss  0.5036 | ms/batch 7470.18 |
-----------------------------------------------------------------------
| epoch  48 | step   441 | dev_acc  0.3361 | test_acc  0.2884 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.48
| step   449 |  lr: 0.0000100 | loss  0.4856 | ms/batch 7960.74 |
-----------------------------------------------------------------------
| epoch  49 | step   450 | dev_acc  0.3033 | test_acc  0.2744 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.49
-----------------------------------------------------------------------
| epoch  50 | step   459 | dev_acc  0.3361 | test_acc  0.2977 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.50
| step   459 |  lr: 0.0000100 | loss  0.4298 | ms/batch  950.32 |
-----------------------------------------------------------------------
| epoch  51 | step   468 | dev_acc  0.3443 | test_acc  0.3023 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.51
| step   469 |  lr: 0.0000100 | loss  0.4049 | ms/batch 1870.59 |
-----------------------------------------------------------------------
| epoch  52 | step   477 | dev_acc  0.3607 | test_acc  0.3070 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.52
| step   479 |  lr: 0.0000100 | loss  0.3837 | ms/batch 2802.98 |
-----------------------------------------------------------------------
| epoch  53 | step   486 | dev_acc  0.3279 | test_acc  0.2744 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.53
| step   489 |  lr: 0.0000100 | loss  0.3443 | ms/batch 3740.75 |
-----------------------------------------------------------------------
| epoch  54 | step   495 | dev_acc  0.3197 | test_acc  0.2791 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.54
| step   499 |  lr: 0.0000100 | loss  0.3322 | ms/batch 4672.08 |
-----------------------------------------------------------------------
| epoch  55 | step   504 | dev_acc  0.3197 | test_acc  0.2744 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.55
| step   509 |  lr: 0.0000100 | loss  0.3535 | ms/batch 5608.61 |
-----------------------------------------------------------------------
| epoch  56 | step   513 | dev_acc  0.3115 | test_acc  0.3116 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.56
| step   519 |  lr: 0.0000100 | loss  0.2702 | ms/batch 6536.44 |
-----------------------------------------------------------------------
| epoch  57 | step   522 | dev_acc  0.3197 | test_acc  0.2977 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.57
| step   529 |  lr: 0.0000100 | loss  0.2675 | ms/batch 7470.51 |
-----------------------------------------------------------------------
| epoch  58 | step   531 | dev_acc  0.3033 | test_acc  0.2977 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.58
| step   539 |  lr: 0.0000100 | loss  0.2717 | ms/batch 7962.12 |
-----------------------------------------------------------------------
| epoch  59 | step   540 | dev_acc  0.3197 | test_acc  0.3209 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.59
-----------------------------------------------------------------------
| epoch  60 | step   549 | dev_acc  0.3115 | test_acc  0.3023 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.60
| step   549 |  lr: 0.0000100 | loss  0.2685 | ms/batch  943.34 |
-----------------------------------------------------------------------
| epoch  61 | step   558 | dev_acc  0.3279 | test_acc  0.2977 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.61
| step   559 |  lr: 0.0000100 | loss  0.2502 | ms/batch 1871.66 |
-----------------------------------------------------------------------
| epoch  62 | step   567 | dev_acc  0.3279 | test_acc  0.3256 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.62
| step   569 |  lr: 0.0000100 | loss  0.2319 | ms/batch 2831.33 |
-----------------------------------------------------------------------
| epoch  63 | step   576 | dev_acc  0.3689 | test_acc  0.3209 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.63
| step   579 |  lr: 0.0000100 | loss  0.2249 | ms/batch 3730.06 |
-----------------------------------------------------------------------
| epoch  64 | step   585 | dev_acc  0.3443 | test_acc  0.3349 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.64
| step   589 |  lr: 0.0000100 | loss  0.1939 | ms/batch 4664.22 |
-----------------------------------------------------------------------
| epoch  65 | step   594 | dev_acc  0.3525 | test_acc  0.2744 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.65
| step   599 |  lr: 0.0000100 | loss  0.2091 | ms/batch 5598.95 |
-----------------------------------------------------------------------
| epoch  66 | step   603 | dev_acc  0.3443 | test_acc  0.3349 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.66
| step   609 |  lr: 0.0000100 | loss  0.1759 | ms/batch 6531.00 |
-----------------------------------------------------------------------
| epoch  67 | step   612 | dev_acc  0.3197 | test_acc  0.3163 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.67
| step   619 |  lr: 0.0000100 | loss  0.1589 | ms/batch 7467.62 |
-----------------------------------------------------------------------
| epoch  68 | step   621 | dev_acc  0.3033 | test_acc  0.3302 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.68
| step   629 |  lr: 0.0000100 | loss  0.2100 | ms/batch 7959.76 |
-----------------------------------------------------------------------
| epoch  69 | step   630 | dev_acc  0.3361 | test_acc  0.3488 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.69
-----------------------------------------------------------------------
| epoch  70 | step   639 | dev_acc  0.3361 | test_acc  0.3442 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.70
| step   639 |  lr: 0.0000100 | loss  0.1649 | ms/batch  931.81 |
-----------------------------------------------------------------------
| epoch  71 | step   648 | dev_acc  0.3443 | test_acc  0.3349 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.71
| step   649 |  lr: 0.0000100 | loss  0.1692 | ms/batch 1868.32 |
-----------------------------------------------------------------------
| epoch  72 | step   657 | dev_acc  0.3197 | test_acc  0.3209 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.72
| step   659 |  lr: 0.0000100 | loss  0.1434 | ms/batch 2804.20 |
-----------------------------------------------------------------------
| epoch  73 | step   666 | dev_acc  0.3033 | test_acc  0.3395 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.73
| step   669 |  lr: 0.0000100 | loss  0.1357 | ms/batch 3751.27 |
-----------------------------------------------------------------------
| epoch  74 | step   675 | dev_acc  0.3115 | test_acc  0.3256 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.74
| step   679 |  lr: 0.0000100 | loss  0.1447 | ms/batch 4681.90 |
-----------------------------------------------------------------------
| epoch  75 | step   684 | dev_acc  0.3689 | test_acc  0.3256 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.75
| step   689 |  lr: 0.0000100 | loss  0.1375 | ms/batch 5615.27 |
-----------------------------------------------------------------------
| epoch  76 | step   693 | dev_acc  0.3115 | test_acc  0.3256 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.76
| step   699 |  lr: 0.0000100 | loss  0.1147 | ms/batch 6538.96 |
-----------------------------------------------------------------------
| epoch  77 | step   702 | dev_acc  0.3033 | test_acc  0.3395 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.77
| step   709 |  lr: 0.0000100 | loss  0.1401 | ms/batch 7497.83 |
-----------------------------------------------------------------------
| epoch  78 | step   711 | dev_acc  0.3279 | test_acc  0.3395 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.78
| step   719 |  lr: 0.0000100 | loss  0.1168 | ms/batch 7959.00 |
-----------------------------------------------------------------------
| epoch  79 | step   720 | dev_acc  0.2951 | test_acc  0.3116 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.79
-----------------------------------------------------------------------
| epoch  80 | step   729 | dev_acc  0.3197 | test_acc  0.3163 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.80
| step   729 |  lr: 0.0000100 | loss  0.1162 | ms/batch  941.47 |
-----------------------------------------------------------------------
| epoch  81 | step   738 | dev_acc  0.2951 | test_acc  0.3442 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.81
| step   739 |  lr: 0.0000100 | loss  0.0903 | ms/batch 1875.19 |
-----------------------------------------------------------------------
| epoch  82 | step   747 | dev_acc  0.2869 | test_acc  0.3488 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.82
| step   749 |  lr: 0.0000100 | loss  0.1006 | ms/batch 2793.29 |
-----------------------------------------------------------------------
| epoch  83 | step   756 | dev_acc  0.2869 | test_acc  0.3023 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.83
| step   759 |  lr: 0.0000100 | loss  0.1054 | ms/batch 3758.29 |
-----------------------------------------------------------------------
| epoch  84 | step   765 | dev_acc  0.2869 | test_acc  0.3349 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.84
| step   769 |  lr: 0.0000100 | loss  0.0816 | ms/batch 4667.84 |
-----------------------------------------------------------------------
| epoch  85 | step   774 | dev_acc  0.3197 | test_acc  0.3209 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.85
| step   779 |  lr: 0.0000100 | loss  0.0730 | ms/batch 5593.63 |
-----------------------------------------------------------------------
| epoch  86 | step   783 | dev_acc  0.3197 | test_acc  0.3116 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.86
| step   789 |  lr: 0.0000100 | loss  0.0747 | ms/batch 6533.54 |
-----------------------------------------------------------------------
| epoch  87 | step   792 | dev_acc  0.3033 | test_acc  0.3163 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.87
| step   799 |  lr: 0.0000100 | loss  0.0955 | ms/batch 7480.86 |
-----------------------------------------------------------------------
| epoch  88 | step   801 | dev_acc  0.3197 | test_acc  0.3302 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.88
| step   809 |  lr: 0.0000100 | loss  0.0904 | ms/batch 7963.72 |
-----------------------------------------------------------------------
| epoch  89 | step   810 | dev_acc  0.3279 | test_acc  0.3070 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.89
-----------------------------------------------------------------------
| epoch  90 | step   819 | dev_acc  0.3115 | test_acc  0.3116 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.90
| step   819 |  lr: 0.0000100 | loss  0.0714 | ms/batch  931.57 |
-----------------------------------------------------------------------
| epoch  91 | step   828 | dev_acc  0.3279 | test_acc  0.3070 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.91
| step   829 |  lr: 0.0000100 | loss  0.0885 | ms/batch 1871.29 |
-----------------------------------------------------------------------
| epoch  92 | step   837 | dev_acc  0.3443 | test_acc  0.3302 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.92
| step   839 |  lr: 0.0000100 | loss  0.0775 | ms/batch 2809.76 |
-----------------------------------------------------------------------
| epoch  93 | step   846 | dev_acc  0.3279 | test_acc  0.3395 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k5__gnndim200__bs128__seed0__20220529_040348/model.pt.93
