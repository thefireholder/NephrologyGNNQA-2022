obiwan
pid: 728670
conda env: greaselm
screen: 

gpu: 0

Namespace(att_head_num=2, batch_size=128, cuda=True, dataset='medqa_usmle', debug=False, decoder_lr=0.001, dev_adj='data/medqa_usmle/graph/dev.graph.adj.pk', dev_statements='data/medqa_usmle/statement/dev.statement.jsonl', drop_partial_batch=False, dropoutf=0.2, dropoutg=0.2, dropouti=0.2, encoder='cambridgeltl/SapBERT-from-PubMedBERT-fulltext', encoder_layer=-1, encoder_lr=5e-05, ent_emb=['ddb'], ent_emb_paths=['data/ddb/ent_emb.npy'], eval_batch_size=2, fc_dim=200, fc_layer_num=0, fill_partial_batch=False, fp16=True, freeze_ent_emb=True, gnn_dim=200, inhouse=False, inhouse_train_qids='data/medqa_usmle/inhouse_split_qids.txt', init_range=0.02, k=5, load_model_path=None, log_interval=10, loss='cross_entropy', lr_schedule='fixed', max_epochs_before_stop=10, max_grad_norm=1.0, max_node_num=200, max_seq_len=512, mini_batch_size=2, mode='train', n_epochs=15, num_relation=34, optim='radam', refreeze_epoch=10000, save_dir='saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20220529_030828', save_model=True, seed=0, simple=False, subsample=1.0, test_adj='data/medqa_usmle/graph/test.graph.adj.pk', test_statements='data/medqa_usmle/statement/test.statement.jsonl', train_adj='data/medqa_usmle/graph/train.graph.adj.pk', train_statements='data/medqa_usmle/statement/train.statement.jsonl', unfreeze_epoch=0, use_cache=True, warmup_steps=150, weight_decay=0.01)
| num_concepts: 9958 |
train_statement_path data/medqa_usmle/statement/train.statement.jsonl
num_choice 4
| ori_adj_len: mu 26.49 sigma 29.73 | adj_len: 27.43 | prune_rate： 0.00 | qc_num: 4.57 | ac_num: 1.06 |
| ori_adj_len: mu 25.20 sigma 28.18 | adj_len: 26.20 | prune_rate： 0.00 | qc_num: 4.34 | ac_num: 1.07 |
| ori_adj_len: mu 26.09 sigma 28.17 | adj_len: 27.06 | prune_rate： 0.00 | qc_num: 4.61 | ac_num: 1.06 |
args.num_relation 34
parameters:
	concept_emb.emb.weight                       	fixed	torch.Size([9958, 768])	device:cuda:0
	concept_emb.cpt_transform.weight             	trainable	torch.Size([200, 768])	device:cuda:0
	concept_emb.cpt_transform.bias               	trainable	torch.Size([200])	device:cuda:0
	svec2nvec.weight                             	trainable	torch.Size([200, 768])	device:cuda:0
	svec2nvec.bias                               	trainable	torch.Size([200])	device:cuda:0
	gnn.emb_node_type.weight                     	trainable	torch.Size([100, 4])	device:cuda:0
	gnn.emb_node_type.bias                       	trainable	torch.Size([100])	device:cuda:0
	gnn.emb_score.weight                         	trainable	torch.Size([100, 100])	device:cuda:0
	gnn.emb_score.bias                           	trainable	torch.Size([100])	device:cuda:0
	gnn.edge_encoder.0.weight                    	trainable	torch.Size([200, 43])	device:cuda:0
	gnn.edge_encoder.0.bias                      	trainable	torch.Size([200])	device:cuda:0
	gnn.edge_encoder.1.weight                    	trainable	torch.Size([200])	device:cuda:0
	gnn.edge_encoder.1.bias                      	trainable	torch.Size([200])	device:cuda:0
	gnn.edge_encoder.3.weight                    	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.edge_encoder.3.bias                      	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.0.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.0.linear_key.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.0.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.0.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.0.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:0
	gnn.gnn_layers.0.linear_query.bias           	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.0.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.0.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.0.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.0.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.0.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.0.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.1.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.1.linear_key.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.1.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.1.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.1.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:0
	gnn.gnn_layers.1.linear_query.bias           	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.1.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.1.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.1.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.1.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.1.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.1.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.2.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.2.linear_key.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.2.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.2.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.2.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:0
	gnn.gnn_layers.2.linear_query.bias           	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.2.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.2.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.2.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.2.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.2.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.2.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.3.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.3.linear_key.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.3.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.3.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.3.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:0
	gnn.gnn_layers.3.linear_query.bias           	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.3.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.3.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.3.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.3.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.3.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.3.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.4.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.4.linear_key.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.4.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.4.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.4.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:0
	gnn.gnn_layers.4.linear_query.bias           	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.4.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.4.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.4.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.4.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.4.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.4.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.Vh.weight                                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.Vh.bias                                  	trainable	torch.Size([200])	device:cuda:0
	gnn.Vx.weight                                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.Vx.bias                                  	trainable	torch.Size([200])	device:cuda:0
	pooler.w_qs.weight                           	trainable	torch.Size([200, 768])	device:cuda:0
	pooler.w_qs.bias                             	trainable	torch.Size([200])	device:cuda:0
	pooler.w_ks.weight                           	trainable	torch.Size([200, 200])	device:cuda:0
	pooler.w_ks.bias                             	trainable	torch.Size([200])	device:cuda:0
	pooler.w_vs.weight                           	trainable	torch.Size([200, 200])	device:cuda:0
	pooler.w_vs.bias                             	trainable	torch.Size([200])	device:cuda:0
	fc.layers.0-Linear.weight                    	trainable	torch.Size([1, 1168])	device:cuda:0
	fc.layers.0-Linear.bias                      	trainable	torch.Size([1])	device:cuda:0
	total: 2690369

-----------------------------------------------------------------------
Using fp16 training
| step     9 |  lr: 0.0000500 | loss  1.3914 | ms/batch 9210.51 |
| step    19 |  lr: 0.0000500 | loss  1.4004 | ms/batch 8391.88 |
| step    29 |  lr: 0.0000500 | loss  1.3886 | ms/batch 8376.31 |
| step    39 |  lr: 0.0000500 | loss  1.3940 | ms/batch 8383.89 |
| step    49 |  lr: 0.0000500 | loss  1.3929 | ms/batch 8384.78 |
| step    59 |  lr: 0.0000500 | loss  1.3925 | ms/batch 8405.78 |
| step    69 |  lr: 0.0000500 | loss  1.3907 | ms/batch 8425.87 |
| step    79 |  lr: 0.0000500 | loss  1.3967 | ms/batch 8019.73 |
-----------------------------------------------------------------------
| epoch   0 | step    80 | dev_acc  0.2767 | test_acc  0.2797 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20220529_030828/model.pt.0
| step    89 |  lr: 0.0000500 | loss  1.3921 | ms/batch 8380.08 |
| step    99 |  lr: 0.0000500 | loss  1.3881 | ms/batch 8417.79 |
| step   109 |  lr: 0.0000500 | loss  1.3890 | ms/batch 8387.12 |
| step   119 |  lr: 0.0000500 | loss  1.3903 | ms/batch 8395.09 |
| step   129 |  lr: 0.0000500 | loss  1.3858 | ms/batch 8427.21 |
| step   139 |  lr: 0.0000500 | loss  1.3884 | ms/batch 8401.63 |
| step   149 |  lr: 0.0000500 | loss  1.3919 | ms/batch 8407.78 |
| step   159 |  lr: 0.0000500 | loss  1.3859 | ms/batch 7980.49 |
-----------------------------------------------------------------------
| epoch   1 | step   160 | dev_acc  0.2948 | test_acc  0.2938 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20220529_030828/model.pt.1
| step   169 |  lr: 0.0000500 | loss  1.3707 | ms/batch 8393.04 |
| step   179 |  lr: 0.0000500 | loss  1.3790 | ms/batch 8397.54 |
| step   189 |  lr: 0.0000500 | loss  1.3769 | ms/batch 8387.53 |
| step   199 |  lr: 0.0000500 | loss  1.3696 | ms/batch 8368.60 |
| step   209 |  lr: 0.0000500 | loss  1.3517 | ms/batch 8379.99 |
| step   219 |  lr: 0.0000500 | loss  1.3672 | ms/batch 8371.17 |
| step   229 |  lr: 0.0000500 | loss  1.3466 | ms/batch 8367.10 |
| step   239 |  lr: 0.0000500 | loss  1.3625 | ms/batch 7996.30 |
-----------------------------------------------------------------------
| epoch   2 | step   240 | dev_acc  0.3381 | test_acc  0.3394 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20220529_030828/model.pt.2
| step   249 |  lr: 0.0000500 | loss  1.3219 | ms/batch 8435.76 |
| step   259 |  lr: 0.0000500 | loss  1.3155 | ms/batch 8498.53 |
| step   269 |  lr: 0.0000500 | loss  1.3155 | ms/batch 8434.57 |
