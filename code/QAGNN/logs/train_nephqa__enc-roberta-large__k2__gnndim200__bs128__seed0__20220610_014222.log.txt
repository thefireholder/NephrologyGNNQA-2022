obiwan
pid: 3802327
conda env: greaselm
screen: 

gpu: 0,1

Namespace(att_head_num=2, batch_size=128, cuda=True, dataset='nephqa', debug=False, decoder_lr=0.001, dev_adj='data/nephqa/graph/dev.graph.adj.pk', dev_statements='data/nephqa/statement/dev.statement.jsonl', drop_partial_batch=False, dropoutf=0.2, dropoutg=0.2, dropouti=0.2, encoder='roberta-large', encoder_layer=-1, encoder_lr=1e-05, ent_emb=['tzw'], ent_emb_paths=['data/cpnet/tzw.ent.npy'], eval_batch_size=2, fc_dim=200, fc_layer_num=0, fill_partial_batch=False, fp16=True, freeze_ent_emb=True, gnn_dim=200, inhouse=False, inhouse_train_qids='data/nephqa/inhouse_split_qids.txt', init_range=0.02, k=2, load_model_path=None, log_interval=10, loss='cross_entropy', lr_schedule='fixed', max_epochs_before_stop=50, max_grad_norm=1.0, max_node_num=200, max_seq_len=100, mini_batch_size=1, mode='train', n_epochs=40, num_relation=38, optim='radam', refreeze_epoch=10000, save_dir='saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222', save_model=True, seed=0, simple=False, subsample=1.0, test_adj='data/nephqa/graph/test.graph.adj.pk', test_statements='data/nephqa/statement/test.statement.jsonl', train_adj='data/nephqa/graph/train.graph.adj.pk', train_statements='data/nephqa/statement/train.statement.jsonl', unfreeze_epoch=4, use_cache=True, warmup_steps=150, weight_decay=0.01)
| num_concepts: 799273 |
train_statement_path data/nephqa/statement/train.statement.jsonl
num_choice 5
| ori_adj_len: mu 2513.54 sigma 1590.31 | adj_len: 191.99 | prune_rate： 0.94 | qc_num: 35.95 | ac_num: 5.21 |
| ori_adj_len: mu 2705.23 sigma 1638.22 | adj_len: 193.85 | prune_rate： 0.95 | qc_num: 38.70 | ac_num: 5.55 |
| ori_adj_len: mu 2566.88 sigma 1535.80 | adj_len: 195.00 | prune_rate： 0.96 | qc_num: 36.10 | ac_num: 5.09 |
args.num_relation 38
parameters:
	concept_emb.emb.weight                       	fixed	torch.Size([799273, 1024])	device:cuda:1
	concept_emb.cpt_transform.weight             	trainable	torch.Size([200, 1024])	device:cuda:1
	concept_emb.cpt_transform.bias               	trainable	torch.Size([200])	device:cuda:1
	svec2nvec.weight                             	trainable	torch.Size([200, 1024])	device:cuda:1
	svec2nvec.bias                               	trainable	torch.Size([200])	device:cuda:1
	gnn.emb_node_type.weight                     	trainable	torch.Size([100, 4])	device:cuda:1
	gnn.emb_node_type.bias                       	trainable	torch.Size([100])	device:cuda:1
	gnn.emb_score.weight                         	trainable	torch.Size([100, 100])	device:cuda:1
	gnn.emb_score.bias                           	trainable	torch.Size([100])	device:cuda:1
	gnn.edge_encoder.0.weight                    	trainable	torch.Size([200, 47])	device:cuda:1
	gnn.edge_encoder.0.bias                      	trainable	torch.Size([200])	device:cuda:1
	gnn.edge_encoder.1.weight                    	trainable	torch.Size([200])	device:cuda:1
	gnn.edge_encoder.1.bias                      	trainable	torch.Size([200])	device:cuda:1
	gnn.edge_encoder.3.weight                    	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.edge_encoder.3.bias                      	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.0.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.0.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.0.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.0.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.0.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.1.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.1.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.1.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.1.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.1.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.Vh.weight                                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.Vh.bias                                  	trainable	torch.Size([200])	device:cuda:1
	gnn.Vx.weight                                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.Vx.bias                                  	trainable	torch.Size([200])	device:cuda:1
	pooler.w_qs.weight                           	trainable	torch.Size([200, 1024])	device:cuda:1
	pooler.w_qs.bias                             	trainable	torch.Size([200])	device:cuda:1
	pooler.w_ks.weight                           	trainable	torch.Size([200, 200])	device:cuda:1
	pooler.w_ks.bias                             	trainable	torch.Size([200])	device:cuda:1
	pooler.w_vs.weight                           	trainable	torch.Size([200, 200])	device:cuda:1
	pooler.w_vs.bias                             	trainable	torch.Size([200])	device:cuda:1
	fc.layers.0-Linear.weight                    	trainable	torch.Size([1, 1424])	device:cuda:1
	fc.layers.0-Linear.bias                      	trainable	torch.Size([1])	device:cuda:1
	total: 1640825

-----------------------------------------------------------------------
Using fp16 training
-----------------------------------------------------------------------
| epoch   0 | step     9 | dev_acc  0.1967 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.0
| step     9 |  lr: 0.0000100 | loss  1.6177 | ms/batch  981.29 |
-----------------------------------------------------------------------
| epoch   1 | step    18 | dev_acc  0.2049 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.1
| step    19 |  lr: 0.0000100 | loss  1.6216 | ms/batch 2032.22 |
-----------------------------------------------------------------------
| epoch   2 | step    27 | dev_acc  0.2213 | test_acc  0.2047 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.2
| step    29 |  lr: 0.0000100 | loss  1.6258 | ms/batch 3064.80 |
-----------------------------------------------------------------------
| epoch   3 | step    36 | dev_acc  0.2213 | test_acc  0.2233 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.3
| step    39 |  lr: 0.0000100 | loss  1.6198 | ms/batch 5876.14 |
-----------------------------------------------------------------------
| epoch   4 | step    45 | dev_acc  0.2295 | test_acc  0.2279 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.4
| step    49 |  lr: 0.0000100 | loss  1.6213 | ms/batch 7346.15 |
-----------------------------------------------------------------------
| epoch   5 | step    54 | dev_acc  0.2131 | test_acc  0.2186 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.5
| step    59 |  lr: 0.0000100 | loss  1.6036 | ms/batch 8797.64 |
-----------------------------------------------------------------------
| epoch   6 | step    63 | dev_acc  0.2131 | test_acc  0.2465 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.6
| step    69 |  lr: 0.0000100 | loss  1.6155 | ms/batch 10213.62 |
-----------------------------------------------------------------------
| epoch   7 | step    72 | dev_acc  0.1803 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.7
| step    79 |  lr: 0.0000100 | loss  1.6117 | ms/batch 11729.15 |
-----------------------------------------------------------------------
| epoch   8 | step    81 | dev_acc  0.1885 | test_acc  0.2233 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.8
| step    89 |  lr: 0.0000100 | loss  1.6007 | ms/batch 12508.76 |
-----------------------------------------------------------------------
| epoch   9 | step    90 | dev_acc  0.1721 | test_acc  0.1860 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.9
-----------------------------------------------------------------------
| epoch  10 | step    99 | dev_acc  0.1885 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.10
| step    99 |  lr: 0.0000100 | loss  1.6076 | ms/batch 1431.10 |
-----------------------------------------------------------------------
| epoch  11 | step   108 | dev_acc  0.1803 | test_acc  0.2372 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.11
| step   109 |  lr: 0.0000100 | loss  1.6037 | ms/batch 2927.98 |
-----------------------------------------------------------------------
| epoch  12 | step   117 | dev_acc  0.1721 | test_acc  0.2186 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.12
| step   119 |  lr: 0.0000100 | loss  1.6079 | ms/batch 4429.38 |
-----------------------------------------------------------------------
| epoch  13 | step   126 | dev_acc  0.1885 | test_acc  0.2326 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.13
| step   129 |  lr: 0.0000100 | loss  1.6034 | ms/batch 5920.01 |
-----------------------------------------------------------------------
| epoch  14 | step   135 | dev_acc  0.1885 | test_acc  0.2279 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.14
| step   139 |  lr: 0.0000100 | loss  1.6071 | ms/batch 7236.54 |
-----------------------------------------------------------------------
| epoch  15 | step   144 | dev_acc  0.1967 | test_acc  0.2279 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.15
| step   149 |  lr: 0.0000100 | loss  1.6056 | ms/batch 8856.80 |
-----------------------------------------------------------------------
| epoch  16 | step   153 | dev_acc  0.1885 | test_acc  0.2279 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.16
| step   159 |  lr: 0.0000100 | loss  1.5984 | ms/batch 10222.51 |
-----------------------------------------------------------------------
| epoch  17 | step   162 | dev_acc  0.1885 | test_acc  0.2047 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.17
| step   169 |  lr: 0.0000100 | loss  1.5984 | ms/batch 11714.36 |
-----------------------------------------------------------------------
| epoch  18 | step   171 | dev_acc  0.1967 | test_acc  0.2279 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.18
| step   179 |  lr: 0.0000100 | loss  1.6036 | ms/batch 12473.98 |
-----------------------------------------------------------------------
| epoch  19 | step   180 | dev_acc  0.1803 | test_acc  0.2186 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.19
-----------------------------------------------------------------------
| epoch  20 | step   189 | dev_acc  0.1803 | test_acc  0.2465 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.20
| step   189 |  lr: 0.0000100 | loss  1.5979 | ms/batch 1474.31 |
-----------------------------------------------------------------------
| epoch  21 | step   198 | dev_acc  0.1885 | test_acc  0.2558 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.21
| step   199 |  lr: 0.0000100 | loss  1.5940 | ms/batch 2987.17 |
-----------------------------------------------------------------------
| epoch  22 | step   207 | dev_acc  0.1803 | test_acc  0.2279 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.22
| step   209 |  lr: 0.0000100 | loss  1.5812 | ms/batch 4421.47 |
-----------------------------------------------------------------------
| epoch  23 | step   216 | dev_acc  0.1885 | test_acc  0.2233 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.23
| step   219 |  lr: 0.0000100 | loss  1.5873 | ms/batch 5921.61 |
-----------------------------------------------------------------------
| epoch  24 | step   225 | dev_acc  0.1803 | test_acc  0.2419 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.24
| step   229 |  lr: 0.0000100 | loss  1.5870 | ms/batch 7324.17 |
-----------------------------------------------------------------------
| epoch  25 | step   234 | dev_acc  0.2131 | test_acc  0.2326 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.25
| step   239 |  lr: 0.0000100 | loss  1.5732 | ms/batch 8805.27 |
-----------------------------------------------------------------------
| epoch  26 | step   243 | dev_acc  0.2213 | test_acc  0.2419 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.26
| step   249 |  lr: 0.0000100 | loss  1.5830 | ms/batch 10248.29 |
-----------------------------------------------------------------------
| epoch  27 | step   252 | dev_acc  0.2377 | test_acc  0.2233 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.27
| step   259 |  lr: 0.0000100 | loss  1.5570 | ms/batch 11723.51 |
-----------------------------------------------------------------------
| epoch  28 | step   261 | dev_acc  0.1885 | test_acc  0.2140 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.28
| step   269 |  lr: 0.0000100 | loss  1.5527 | ms/batch 12488.96 |
-----------------------------------------------------------------------
| epoch  29 | step   270 | dev_acc  0.1885 | test_acc  0.2279 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.29
-----------------------------------------------------------------------
| epoch  30 | step   279 | dev_acc  0.1967 | test_acc  0.2372 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.30
| step   279 |  lr: 0.0000100 | loss  1.5401 | ms/batch 1447.81 |
-----------------------------------------------------------------------
| epoch  31 | step   288 | dev_acc  0.2377 | test_acc  0.2651 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.31
| step   289 |  lr: 0.0000100 | loss  1.5018 | ms/batch 2940.72 |
-----------------------------------------------------------------------
| epoch  32 | step   297 | dev_acc  0.2377 | test_acc  0.2558 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.32
| step   299 |  lr: 0.0000100 | loss  1.4655 | ms/batch 4358.80 |
-----------------------------------------------------------------------
| epoch  33 | step   306 | dev_acc  0.2541 | test_acc  0.2419 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.33
| step   309 |  lr: 0.0000100 | loss  1.4370 | ms/batch 5846.60 |
-----------------------------------------------------------------------
| epoch  34 | step   315 | dev_acc  0.2705 | test_acc  0.2884 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.34
| step   319 |  lr: 0.0000100 | loss  1.3777 | ms/batch 7447.63 |
-----------------------------------------------------------------------
| epoch  35 | step   324 | dev_acc  0.2787 | test_acc  0.3070 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.35
| step   329 |  lr: 0.0000100 | loss  1.3247 | ms/batch 8783.68 |
-----------------------------------------------------------------------
| epoch  36 | step   333 | dev_acc  0.2787 | test_acc  0.2744 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.36
| step   339 |  lr: 0.0000100 | loss  1.2899 | ms/batch 10298.43 |
-----------------------------------------------------------------------
| epoch  37 | step   342 | dev_acc  0.2869 | test_acc  0.3209 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.37
| step   349 |  lr: 0.0000100 | loss  1.1767 | ms/batch 11699.82 |
-----------------------------------------------------------------------
| epoch  38 | step   351 | dev_acc  0.2787 | test_acc  0.3116 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.38
| step   359 |  lr: 0.0000100 | loss  1.1387 | ms/batch 12508.85 |
-----------------------------------------------------------------------
| epoch  39 | step   360 | dev_acc  0.3197 | test_acc  0.3023 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k2__gnndim200__bs128__seed0__20220610_014222/model.pt.39
