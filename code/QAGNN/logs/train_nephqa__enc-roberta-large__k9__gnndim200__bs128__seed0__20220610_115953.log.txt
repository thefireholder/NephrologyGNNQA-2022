obiwan
pid: 3861083
conda env: greaselm
screen: 

gpu: 0,1

Namespace(att_head_num=2, batch_size=128, cuda=True, dataset='nephqa', debug=False, decoder_lr=0.001, dev_adj='data/nephqa/graph/dev.graph.adj.pk', dev_statements='data/nephqa/statement/dev.statement.jsonl', drop_partial_batch=False, dropoutf=0.2, dropoutg=0.2, dropouti=0.2, encoder='roberta-large', encoder_layer=-1, encoder_lr=1e-05, ent_emb=['tzw'], ent_emb_paths=['data/cpnet/tzw.ent.npy'], eval_batch_size=2, fc_dim=200, fc_layer_num=0, fill_partial_batch=False, fp16=True, freeze_ent_emb=True, gnn_dim=200, inhouse=False, inhouse_train_qids='data/nephqa/inhouse_split_qids.txt', init_range=0.02, k=9, load_model_path=None, log_interval=10, loss='cross_entropy', lr_schedule='fixed', max_epochs_before_stop=50, max_grad_norm=1.0, max_node_num=200, max_seq_len=100, mini_batch_size=1, mode='train', n_epochs=40, num_relation=38, optim='radam', refreeze_epoch=10000, save_dir='saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953', save_model=True, seed=0, simple=False, subsample=1.0, test_adj='data/nephqa/graph/test.graph.adj.pk', test_statements='data/nephqa/statement/test.statement.jsonl', train_adj='data/nephqa/graph/train.graph.adj.pk', train_statements='data/nephqa/statement/train.statement.jsonl', unfreeze_epoch=4, use_cache=True, warmup_steps=150, weight_decay=0.01)
| num_concepts: 799273 |
train_statement_path data/nephqa/statement/train.statement.jsonl
num_choice 5
| ori_adj_len: mu 2513.54 sigma 1590.31 | adj_len: 191.99 | prune_rate： 0.94 | qc_num: 35.95 | ac_num: 5.21 |
| ori_adj_len: mu 2705.23 sigma 1638.22 | adj_len: 193.85 | prune_rate： 0.95 | qc_num: 38.70 | ac_num: 5.55 |
| ori_adj_len: mu 2566.88 sigma 1535.80 | adj_len: 195.00 | prune_rate： 0.96 | qc_num: 36.10 | ac_num: 5.09 |
args.num_relation 38
parameters:
	concept_emb.emb.weight                       	fixed	torch.Size([799273, 1024])	device:cuda:1
	concept_emb.cpt_transform.weight             	trainable	torch.Size([200, 1024])	device:cuda:1
	concept_emb.cpt_transform.bias               	trainable	torch.Size([200])	device:cuda:1
	svec2nvec.weight                             	trainable	torch.Size([200, 1024])	device:cuda:1
	svec2nvec.bias                               	trainable	torch.Size([200])	device:cuda:1
	gnn.emb_node_type.weight                     	trainable	torch.Size([100, 4])	device:cuda:1
	gnn.emb_node_type.bias                       	trainable	torch.Size([100])	device:cuda:1
	gnn.emb_score.weight                         	trainable	torch.Size([100, 100])	device:cuda:1
	gnn.emb_score.bias                           	trainable	torch.Size([100])	device:cuda:1
	gnn.edge_encoder.0.weight                    	trainable	torch.Size([200, 47])	device:cuda:1
	gnn.edge_encoder.0.bias                      	trainable	torch.Size([200])	device:cuda:1
	gnn.edge_encoder.1.weight                    	trainable	torch.Size([200])	device:cuda:1
	gnn.edge_encoder.1.bias                      	trainable	torch.Size([200])	device:cuda:1
	gnn.edge_encoder.3.weight                    	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.edge_encoder.3.bias                      	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.0.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.0.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.0.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.0.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.0.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.1.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.1.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.1.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.1.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.1.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.2.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.2.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.2.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.2.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.2.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.3.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.3.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.3.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.3.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.3.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.4.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.4.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.4.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.4.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.4.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.5.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.5.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.5.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.5.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.5.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.5.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.5.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.5.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.5.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.5.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.5.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.5.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.6.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.6.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.6.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.6.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.6.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.6.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.6.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.6.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.6.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.6.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.6.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.6.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.7.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.7.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.7.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.7.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.7.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.7.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.7.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.7.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.7.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.7.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.7.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.7.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.8.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.8.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.8.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.8.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.8.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.8.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.8.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.8.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.8.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.8.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.8.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.8.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.Vh.weight                                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.Vh.bias                                  	trainable	torch.Size([200])	device:cuda:1
	gnn.Vx.weight                                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.Vx.bias                                  	trainable	torch.Size([200])	device:cuda:1
	pooler.w_qs.weight                           	trainable	torch.Size([200, 1024])	device:cuda:1
	pooler.w_qs.bias                             	trainable	torch.Size([200])	device:cuda:1
	pooler.w_ks.weight                           	trainable	torch.Size([200, 200])	device:cuda:1
	pooler.w_ks.bias                             	trainable	torch.Size([200])	device:cuda:1
	pooler.w_vs.weight                           	trainable	torch.Size([200, 200])	device:cuda:1
	pooler.w_vs.bias                             	trainable	torch.Size([200])	device:cuda:1
	fc.layers.0-Linear.weight                    	trainable	torch.Size([1, 1424])	device:cuda:1
	fc.layers.0-Linear.bias                      	trainable	torch.Size([1])	device:cuda:1
	total: 4450625

-----------------------------------------------------------------------
Using fp16 training
-----------------------------------------------------------------------
| epoch   0 | step     9 | dev_acc  0.1557 | test_acc  0.1814 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.0
| step     9 |  lr: 0.0000100 | loss  1.6225 | ms/batch 3514.53 |
-----------------------------------------------------------------------
| epoch   1 | step    18 | dev_acc  0.1311 | test_acc  0.2047 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.1
| step    19 |  lr: 0.0000100 | loss  1.6110 | ms/batch 7241.07 |
-----------------------------------------------------------------------
| epoch   2 | step    27 | dev_acc  0.1311 | test_acc  0.2140 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.2
| step    29 |  lr: 0.0000100 | loss  1.6069 | ms/batch 10744.35 |
-----------------------------------------------------------------------
| epoch   3 | step    36 | dev_acc  0.1475 | test_acc  0.1907 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.3
| step    39 |  lr: 0.0000100 | loss  1.6184 | ms/batch 15866.51 |
-----------------------------------------------------------------------
| epoch   4 | step    45 | dev_acc  0.1557 | test_acc  0.2140 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.4
| step    49 |  lr: 0.0000100 | loss  1.6184 | ms/batch 20582.32 |
-----------------------------------------------------------------------
| epoch   5 | step    54 | dev_acc  0.1311 | test_acc  0.2000 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.5
| step    59 |  lr: 0.0000100 | loss  1.6199 | ms/batch 24473.15 |
-----------------------------------------------------------------------
| epoch   6 | step    63 | dev_acc  0.1393 | test_acc  0.2047 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.6
| step    69 |  lr: 0.0000100 | loss  1.6094 | ms/batch 28337.01 |
-----------------------------------------------------------------------
| epoch   7 | step    72 | dev_acc  0.1475 | test_acc  0.2372 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.7
| step    79 |  lr: 0.0000100 | loss  1.6168 | ms/batch 32593.54 |
-----------------------------------------------------------------------
| epoch   8 | step    81 | dev_acc  0.1721 | test_acc  0.2186 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.8
| step    89 |  lr: 0.0000100 | loss  1.6105 | ms/batch 34578.89 |
-----------------------------------------------------------------------
| epoch   9 | step    90 | dev_acc  0.1557 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.9
-----------------------------------------------------------------------
| epoch  10 | step    99 | dev_acc  0.1557 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.10
| step    99 |  lr: 0.0000100 | loss  1.6012 | ms/batch 4113.49 |
-----------------------------------------------------------------------
| epoch  11 | step   108 | dev_acc  0.1475 | test_acc  0.2233 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.11
| step   109 |  lr: 0.0000100 | loss  1.6094 | ms/batch 7963.47 |
-----------------------------------------------------------------------
| epoch  12 | step   117 | dev_acc  0.1393 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.12
| step   119 |  lr: 0.0000100 | loss  1.6146 | ms/batch 12151.16 |
-----------------------------------------------------------------------
| epoch  13 | step   126 | dev_acc  0.1393 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.13
| step   129 |  lr: 0.0000100 | loss  1.5990 | ms/batch 16037.90 |
-----------------------------------------------------------------------
| epoch  14 | step   135 | dev_acc  0.1639 | test_acc  0.2326 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.14
| step   139 |  lr: 0.0000100 | loss  1.5985 | ms/batch 20096.57 |
-----------------------------------------------------------------------
| epoch  15 | step   144 | dev_acc  0.1721 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.15
| step   149 |  lr: 0.0000100 | loss  1.6012 | ms/batch 24315.19 |
-----------------------------------------------------------------------
| epoch  16 | step   153 | dev_acc  0.1639 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.16
| step   159 |  lr: 0.0000100 | loss  1.6012 | ms/batch 28485.40 |
-----------------------------------------------------------------------
| epoch  17 | step   162 | dev_acc  0.1639 | test_acc  0.2233 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.17
| step   169 |  lr: 0.0000100 | loss  1.5918 | ms/batch 32396.72 |
-----------------------------------------------------------------------
| epoch  18 | step   171 | dev_acc  0.1967 | test_acc  0.2465 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.18
| step   179 |  lr: 0.0000100 | loss  1.5926 | ms/batch 34601.23 |
-----------------------------------------------------------------------
| epoch  19 | step   180 | dev_acc  0.2049 | test_acc  0.1953 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.19
-----------------------------------------------------------------------
| epoch  20 | step   189 | dev_acc  0.2213 | test_acc  0.2140 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.20
| step   189 |  lr: 0.0000100 | loss  1.5805 | ms/batch 3822.64 |
-----------------------------------------------------------------------
| epoch  21 | step   198 | dev_acc  0.2213 | test_acc  0.2140 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.21
| step   199 |  lr: 0.0000100 | loss  1.5819 | ms/batch 7960.54 |
-----------------------------------------------------------------------
| epoch  22 | step   207 | dev_acc  0.2049 | test_acc  0.2419 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.22
| step   209 |  lr: 0.0000100 | loss  1.5734 | ms/batch 12033.68 |
-----------------------------------------------------------------------
| epoch  23 | step   216 | dev_acc  0.2131 | test_acc  0.2372 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.23
| step   219 |  lr: 0.0000100 | loss  1.5462 | ms/batch 16274.73 |
-----------------------------------------------------------------------
| epoch  24 | step   225 | dev_acc  0.1967 | test_acc  0.2140 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.24
| step   229 |  lr: 0.0000100 | loss  1.5461 | ms/batch 20328.86 |
-----------------------------------------------------------------------
| epoch  25 | step   234 | dev_acc  0.1967 | test_acc  0.2512 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k9__gnndim200__bs128__seed0__20220610_115953/model.pt.25
