obiwan
pid: 3802835
conda env: greaselm
screen: 

gpu: 0,1

Namespace(att_head_num=2, batch_size=128, cuda=True, dataset='nephqa', debug=False, decoder_lr=0.001, dev_adj='data/nephqa/graph/dev.graph.adj.pk', dev_statements='data/nephqa/statement/dev.statement.jsonl', drop_partial_batch=False, dropoutf=0.2, dropoutg=0.2, dropouti=0.2, encoder='roberta-large', encoder_layer=-1, encoder_lr=1e-05, ent_emb=['tzw'], ent_emb_paths=['data/cpnet/tzw.ent.npy'], eval_batch_size=2, fc_dim=200, fc_layer_num=0, fill_partial_batch=False, fp16=True, freeze_ent_emb=True, gnn_dim=200, inhouse=False, inhouse_train_qids='data/nephqa/inhouse_split_qids.txt', init_range=0.02, k=7, load_model_path=None, log_interval=10, loss='cross_entropy', lr_schedule='fixed', max_epochs_before_stop=50, max_grad_norm=1.0, max_node_num=200, max_seq_len=100, mini_batch_size=1, mode='train', n_epochs=40, num_relation=38, optim='radam', refreeze_epoch=10000, save_dir='saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335', save_model=True, seed=0, simple=False, subsample=1.0, test_adj='data/nephqa/graph/test.graph.adj.pk', test_statements='data/nephqa/statement/test.statement.jsonl', train_adj='data/nephqa/graph/train.graph.adj.pk', train_statements='data/nephqa/statement/train.statement.jsonl', unfreeze_epoch=4, use_cache=True, warmup_steps=150, weight_decay=0.01)
| num_concepts: 799273 |
train_statement_path data/nephqa/statement/train.statement.jsonl
num_choice 5
| ori_adj_len: mu 2513.54 sigma 1590.31 | adj_len: 191.99 | prune_rate： 0.94 | qc_num: 35.95 | ac_num: 5.21 |
| ori_adj_len: mu 2705.23 sigma 1638.22 | adj_len: 193.85 | prune_rate： 0.95 | qc_num: 38.70 | ac_num: 5.55 |
| ori_adj_len: mu 2566.88 sigma 1535.80 | adj_len: 195.00 | prune_rate： 0.96 | qc_num: 36.10 | ac_num: 5.09 |
args.num_relation 38
parameters:
	concept_emb.emb.weight                       	fixed	torch.Size([799273, 1024])	device:cuda:1
	concept_emb.cpt_transform.weight             	trainable	torch.Size([200, 1024])	device:cuda:1
	concept_emb.cpt_transform.bias               	trainable	torch.Size([200])	device:cuda:1
	svec2nvec.weight                             	trainable	torch.Size([200, 1024])	device:cuda:1
	svec2nvec.bias                               	trainable	torch.Size([200])	device:cuda:1
	gnn.emb_node_type.weight                     	trainable	torch.Size([100, 4])	device:cuda:1
	gnn.emb_node_type.bias                       	trainable	torch.Size([100])	device:cuda:1
	gnn.emb_score.weight                         	trainable	torch.Size([100, 100])	device:cuda:1
	gnn.emb_score.bias                           	trainable	torch.Size([100])	device:cuda:1
	gnn.edge_encoder.0.weight                    	trainable	torch.Size([200, 47])	device:cuda:1
	gnn.edge_encoder.0.bias                      	trainable	torch.Size([200])	device:cuda:1
	gnn.edge_encoder.1.weight                    	trainable	torch.Size([200])	device:cuda:1
	gnn.edge_encoder.1.bias                      	trainable	torch.Size([200])	device:cuda:1
	gnn.edge_encoder.3.weight                    	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.edge_encoder.3.bias                      	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.0.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.0.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.0.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.0.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.0.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.0.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.1.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.1.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.1.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.1.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.1.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.1.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.2.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.2.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.2.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.2.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.2.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.2.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.3.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.3.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.3.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.3.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.3.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.3.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.4.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.4.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.4.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.4.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.4.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.4.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.5.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.5.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.5.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.5.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.5.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.5.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.5.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.5.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.5.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.5.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.5.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.5.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.6.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.6.linear_key.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.6.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:1
	gnn.gnn_layers.6.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.6.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:1
	gnn.gnn_layers.6.linear_query.bias           	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.6.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.6.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.6.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.6.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.gnn_layers.6.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.gnn_layers.6.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:1
	gnn.Vh.weight                                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.Vh.bias                                  	trainable	torch.Size([200])	device:cuda:1
	gnn.Vx.weight                                	trainable	torch.Size([200, 200])	device:cuda:1
	gnn.Vx.bias                                  	trainable	torch.Size([200])	device:cuda:1
	pooler.w_qs.weight                           	trainable	torch.Size([200, 1024])	device:cuda:1
	pooler.w_qs.bias                             	trainable	torch.Size([200])	device:cuda:1
	pooler.w_ks.weight                           	trainable	torch.Size([200, 200])	device:cuda:1
	pooler.w_ks.bias                             	trainable	torch.Size([200])	device:cuda:1
	pooler.w_vs.weight                           	trainable	torch.Size([200, 200])	device:cuda:1
	pooler.w_vs.bias                             	trainable	torch.Size([200])	device:cuda:1
	fc.layers.0-Linear.weight                    	trainable	torch.Size([1, 1424])	device:cuda:1
	fc.layers.0-Linear.bias                      	trainable	torch.Size([1])	device:cuda:1
	total: 3647825

-----------------------------------------------------------------------
Using fp16 training
-----------------------------------------------------------------------
| epoch   0 | step     9 | dev_acc  0.1885 | test_acc  0.1674 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.0
| step     9 |  lr: 0.0000100 | loss  1.6195 | ms/batch 2854.79 |
-----------------------------------------------------------------------
| epoch   1 | step    18 | dev_acc  0.1885 | test_acc  0.2047 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.1
| step    19 |  lr: 0.0000100 | loss  1.6243 | ms/batch 5802.27 |
-----------------------------------------------------------------------
| epoch   2 | step    27 | dev_acc  0.2049 | test_acc  0.2233 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.2
| step    29 |  lr: 0.0000100 | loss  1.6220 | ms/batch 8483.73 |
-----------------------------------------------------------------------
| epoch   3 | step    36 | dev_acc  0.2131 | test_acc  0.2186 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.3
| step    39 |  lr: 0.0000100 | loss  1.6285 | ms/batch 13317.55 |
-----------------------------------------------------------------------
| epoch   4 | step    45 | dev_acc  0.1885 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.4
| step    49 |  lr: 0.0000100 | loss  1.6137 | ms/batch 16698.75 |
-----------------------------------------------------------------------
| epoch   5 | step    54 | dev_acc  0.1557 | test_acc  0.2047 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.5
| step    59 |  lr: 0.0000100 | loss  1.6154 | ms/batch 19726.98 |
-----------------------------------------------------------------------
| epoch   6 | step    63 | dev_acc  0.1393 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.6
| step    69 |  lr: 0.0000100 | loss  1.6146 | ms/batch 23292.49 |
-----------------------------------------------------------------------
| epoch   7 | step    72 | dev_acc  0.1393 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.7
| step    79 |  lr: 0.0000100 | loss  1.6131 | ms/batch 26530.40 |
-----------------------------------------------------------------------
| epoch   8 | step    81 | dev_acc  0.1311 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.8
| step    89 |  lr: 0.0000100 | loss  1.6089 | ms/batch 28356.14 |
-----------------------------------------------------------------------
| epoch   9 | step    90 | dev_acc  0.1557 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.9
-----------------------------------------------------------------------
| epoch  10 | step    99 | dev_acc  0.1803 | test_acc  0.1953 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.10
| step    99 |  lr: 0.0000100 | loss  1.6025 | ms/batch 3353.30 |
-----------------------------------------------------------------------
| epoch  11 | step   108 | dev_acc  0.1639 | test_acc  0.1953 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.11
| step   109 |  lr: 0.0000100 | loss  1.6029 | ms/batch 6701.37 |
-----------------------------------------------------------------------
| epoch  12 | step   117 | dev_acc  0.1475 | test_acc  0.1953 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.12
| step   119 |  lr: 0.0000100 | loss  1.6004 | ms/batch 9977.06 |
-----------------------------------------------------------------------
| epoch  13 | step   126 | dev_acc  0.1475 | test_acc  0.1907 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.13
| step   129 |  lr: 0.0000100 | loss  1.5956 | ms/batch 13431.36 |
-----------------------------------------------------------------------
| epoch  14 | step   135 | dev_acc  0.1475 | test_acc  0.2000 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.14
| step   139 |  lr: 0.0000100 | loss  1.6168 | ms/batch 16631.62 |
-----------------------------------------------------------------------
| epoch  15 | step   144 | dev_acc  0.1557 | test_acc  0.2326 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.15
| step   149 |  lr: 0.0000100 | loss  1.6034 | ms/batch 19981.14 |
-----------------------------------------------------------------------
| epoch  16 | step   153 | dev_acc  0.1393 | test_acc  0.2279 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.16
| step   159 |  lr: 0.0000100 | loss  1.5970 | ms/batch 23270.84 |
-----------------------------------------------------------------------
| epoch  17 | step   162 | dev_acc  0.1557 | test_acc  0.1953 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.17
| step   169 |  lr: 0.0000100 | loss  1.6115 | ms/batch 26559.47 |
-----------------------------------------------------------------------
| epoch  18 | step   171 | dev_acc  0.1639 | test_acc  0.2047 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.18
| step   179 |  lr: 0.0000100 | loss  1.5975 | ms/batch 28347.16 |
-----------------------------------------------------------------------
| epoch  19 | step   180 | dev_acc  0.1721 | test_acc  0.1953 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.19
-----------------------------------------------------------------------
| epoch  20 | step   189 | dev_acc  0.1557 | test_acc  0.2093 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.20
| step   189 |  lr: 0.0000100 | loss  1.5949 | ms/batch 3342.65 |
-----------------------------------------------------------------------
| epoch  21 | step   198 | dev_acc  0.1885 | test_acc  0.2233 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.21
| step   199 |  lr: 0.0000100 | loss  1.5837 | ms/batch 6556.79 |
-----------------------------------------------------------------------
| epoch  22 | step   207 | dev_acc  0.2295 | test_acc  0.2326 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.22
| step   209 |  lr: 0.0000100 | loss  1.5597 | ms/batch 10028.26 |
-----------------------------------------------------------------------
| epoch  23 | step   216 | dev_acc  0.2541 | test_acc  0.2372 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.23
| step   219 |  lr: 0.0000100 | loss  1.5530 | ms/batch 13241.06 |
-----------------------------------------------------------------------
| epoch  24 | step   225 | dev_acc  0.2295 | test_acc  0.2233 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.24
| step   229 |  lr: 0.0000100 | loss  1.5529 | ms/batch 16870.90 |
-----------------------------------------------------------------------
| epoch  25 | step   234 | dev_acc  0.2213 | test_acc  0.2186 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.25
| step   239 |  lr: 0.0000100 | loss  1.5227 | ms/batch 19981.14 |
-----------------------------------------------------------------------
| epoch  26 | step   243 | dev_acc  0.2869 | test_acc  0.2372 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.26
| step   249 |  lr: 0.0000100 | loss  1.5205 | ms/batch 23410.51 |
-----------------------------------------------------------------------
| epoch  27 | step   252 | dev_acc  0.3033 | test_acc  0.2605 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.27
| step   259 |  lr: 0.0000100 | loss  1.4930 | ms/batch 26541.91 |
-----------------------------------------------------------------------
| epoch  28 | step   261 | dev_acc  0.2623 | test_acc  0.2698 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.28
| step   269 |  lr: 0.0000100 | loss  1.4577 | ms/batch 28352.43 |
-----------------------------------------------------------------------
| epoch  29 | step   270 | dev_acc  0.2623 | test_acc  0.2558 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.29
-----------------------------------------------------------------------
| epoch  30 | step   279 | dev_acc  0.2951 | test_acc  0.2791 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.30
| step   279 |  lr: 0.0000100 | loss  1.4441 | ms/batch 3374.39 |
-----------------------------------------------------------------------
| epoch  31 | step   288 | dev_acc  0.2705 | test_acc  0.2558 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.31
| step   289 |  lr: 0.0000100 | loss  1.4040 | ms/batch 6609.53 |
-----------------------------------------------------------------------
| epoch  32 | step   297 | dev_acc  0.3033 | test_acc  0.2977 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.32
| step   299 |  lr: 0.0000100 | loss  1.3703 | ms/batch 9991.78 |
-----------------------------------------------------------------------
| epoch  33 | step   306 | dev_acc  0.3033 | test_acc  0.2930 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.33
| step   309 |  lr: 0.0000100 | loss  1.3236 | ms/batch 13333.54 |
-----------------------------------------------------------------------
| epoch  34 | step   315 | dev_acc  0.2213 | test_acc  0.2233 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.34
| step   319 |  lr: 0.0000100 | loss  1.3306 | ms/batch 16794.65 |
-----------------------------------------------------------------------
| epoch  35 | step   324 | dev_acc  0.2705 | test_acc  0.2930 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.35
| step   329 |  lr: 0.0000100 | loss  1.2457 | ms/batch 19905.46 |
-----------------------------------------------------------------------
| epoch  36 | step   333 | dev_acc  0.2705 | test_acc  0.2140 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.36
| step   339 |  lr: 0.0000100 | loss  1.2377 | ms/batch 23269.19 |
-----------------------------------------------------------------------
| epoch  37 | step   342 | dev_acc  0.2295 | test_acc  0.2372 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.37
| step   349 |  lr: 0.0000100 | loss  1.1747 | ms/batch 26575.59 |
-----------------------------------------------------------------------
| epoch  38 | step   351 | dev_acc  0.3197 | test_acc  0.2791 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.38
| step   359 |  lr: 0.0000100 | loss  1.1145 | ms/batch 28333.01 |
-----------------------------------------------------------------------
| epoch  39 | step   360 | dev_acc  0.3279 | test_acc  0.2605 |
-----------------------------------------------------------------------
model saved to saved_models/nephqa/enc-roberta-large__k7__gnndim200__bs128__seed0__20220610_055335/model.pt.39
